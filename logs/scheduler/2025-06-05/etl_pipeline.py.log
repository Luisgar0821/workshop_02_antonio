[2025-06-05T01:01:41.689+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:01:41.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:01:41.690+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:01:41.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:01:42.886+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:01:42.879+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:01:42.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:01:42.899+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.212 seconds
[2025-06-05T01:02:14.412+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:14.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:02:14.414+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:02:14.413+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:14.843+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:02:14.838+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:02:14.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:14.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.447 seconds
[2025-06-05T01:02:44.987+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:44.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:02:44.989+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:02:44.989+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:45.417+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:02:45.411+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:02:45.417+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:02:45.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.446 seconds
[2025-06-05T01:03:15.663+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:15.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:03:15.664+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:03:15.664+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:16.103+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:03:16.098+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:03:16.104+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:16.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.456 seconds
[2025-06-05T01:03:46.827+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:46.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:03:46.828+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:03:46.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:47.278+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:03:47.272+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:03:47.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:03:47.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.466 seconds
[2025-06-05T01:04:17.513+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:17.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:04:17.515+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:04:17.514+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:17.946+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:04:17.940+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:04:17.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:17.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.448 seconds
[2025-06-05T01:04:48.199+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:48.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:04:48.200+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:04:48.200+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:48.638+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:04:48.633+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:04:48.639+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:04:48.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.454 seconds
[2025-06-05T01:05:19.351+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:19.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:05:19.352+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:05:19.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:19.774+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:05:19.768+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:05:19.774+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:19.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.437 seconds
[2025-06-05T01:05:50.041+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:50.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:05:50.043+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:05:50.043+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:50.465+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:05:50.459+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:05:50.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:05:50.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.439 seconds
[2025-06-05T01:06:20.607+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:20.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:06:20.608+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:06:20.608+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:21.030+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:06:21.024+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:06:21.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:21.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.437 seconds
[2025-06-05T01:06:51.297+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:51.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:06:51.299+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:06:51.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:51.709+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:06:51.704+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:06:51.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:06:51.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.427 seconds
[2025-06-05T01:07:21.982+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:21.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:07:21.984+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:07:21.983+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:22.394+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:07:22.389+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:07:22.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:22.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.427 seconds
[2025-06-05T01:07:53.114+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:53.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:07:53.115+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:07:53.115+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:53.524+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:07:53.519+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:07:53.524+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:07:53.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.424 seconds
[2025-06-05T01:08:23.828+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:23.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:08:23.829+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:08:23.829+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:24.245+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:08:24.239+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:08:24.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:24.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.431 seconds
[2025-06-05T01:08:54.952+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:54.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:08:54.953+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:08:54.953+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:55.385+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:08:55.380+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:08:55.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:08:55.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.448 seconds
[2025-06-05T01:09:25.625+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:09:25.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:09:25.626+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:09:25.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:09:26.049+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:09:26.043+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:09:26.049+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:09:26.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.439 seconds
[2025-06-05T01:10:10.870+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:10.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:10:10.871+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:10:10.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:11.344+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:10:11.339+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:10:11.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:11.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.491 seconds
[2025-06-05T01:10:41.571+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:41.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:10:41.573+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:10:41.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:42.004+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:10:41.999+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:10:42.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:10:42.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.449 seconds
[2025-06-05T01:11:12.262+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:12.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:11:12.263+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:11:12.263+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:12.699+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:11:12.694+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:11:12.700+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:12.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.453 seconds
[2025-06-05T01:11:42.851+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:42.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:11:42.852+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:11:42.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:43.319+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:11:43.314+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:11:43.319+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:11:43.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.484 seconds
[2025-06-05T01:12:13.540+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:13.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:12:13.542+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:12:13.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:13.970+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:12:13.964+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:12:13.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:13.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.446 seconds
[2025-06-05T01:12:44.242+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:44.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:12:44.243+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:12:44.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:44.680+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:12:44.675+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:12:44.680+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:12:44.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.453 seconds
[2025-06-05T01:13:15.369+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:15.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:13:15.371+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:13:15.370+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:16.299+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:13:16.292+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:13:16.299+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:16.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.944 seconds
[2025-06-05T01:13:47.037+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:47.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:13:47.039+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:13:47.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:47.443+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:13:47.437+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:13:47.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:13:47.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.420 seconds
[2025-06-05T01:14:17.737+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:17.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:14:17.738+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:14:17.738+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:18.277+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:14:18.271+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:14:18.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:18.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.556 seconds
[2025-06-05T01:14:48.853+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:48.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:14:48.855+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:14:48.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:49.261+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:14:49.255+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:14:49.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:14:49.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.422 seconds
[2025-06-05T01:15:22.720+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:15:22.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:15:22.721+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:15:22.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:15:23.109+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:15:23.104+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:15:23.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:15:23.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.404 seconds
[2025-06-05T01:22:20.612+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:20.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:22:20.613+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:22:20.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:21.726+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:22:21.720+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:22:21.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:21.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 1.130 seconds
[2025-06-05T01:22:52.334+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:52.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:22:52.336+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:22:52.335+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:52.751+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:22:52.746+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:22:52.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:22:52.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.432 seconds
[2025-06-05T01:23:23.134+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:23.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:23:23.136+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:23:23.136+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:23.588+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:23:23.583+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:23:23.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:23.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.470 seconds
[2025-06-05T01:23:54.152+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:54.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:23:54.153+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:23:54.153+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:54.583+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:23:54.578+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:23:54.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:23:54.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.447 seconds
[2025-06-05T01:24:24.966+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:24.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:24:24.967+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:24:24.967+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:25.377+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:24:25.371+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:24:25.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:25.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.425 seconds
[2025-06-05T01:24:55.998+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:55.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:24:55.999+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:24:55.999+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:56.406+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:24:56.401+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:24:56.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:24:56.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.423 seconds
[2025-06-05T01:25:26.548+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:26.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:25:26.549+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:25:26.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:26.977+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:25:26.971+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:25:26.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:26.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.446 seconds
[2025-06-05T01:25:57.218+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:57.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:25:57.220+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:25:57.220+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:57.634+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:25:57.628+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:25:57.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:25:57.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.432 seconds
[2025-06-05T01:26:27.903+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:27.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:26:27.905+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:26:27.905+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:28.366+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:26:28.361+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:26:28.367+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:28.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.479 seconds
[2025-06-05T01:26:59.035+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:59.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:26:59.036+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:26:59.036+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:59.440+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:26:59.435+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:26:59.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:26:59.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.421 seconds
[2025-06-05T01:27:29.841+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:27:29.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:27:29.843+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:27:29.842+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:27:30.264+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:27:30.259+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:27:30.265+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:27:30.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.438 seconds
[2025-06-05T01:28:00.855+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:00.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:28:00.856+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:28:00.856+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:01.268+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:28:01.263+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 10, in <module>
    from merge_data.merge import merge_all_data
  File "/opt/airflow/src/merge_data/merge.py", line 22, in <module>
    df_spotify = pl.read_csv(f"{DATA_PROCESSED}/spotify_transformed.csv")
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/_utils/deprecation.py", line 128, in wrapper
    return function(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 546, in read_csv
    df = _read_csv_impl(
  File "/home/airflow/.local/lib/python3.10/site-packages/polars/io/csv/functions.py", line 694, in _read_csv_impl
    pydf = PyDataFrame.read_csv(
FileNotFoundError: No such file or directory (os error 2): /opt/airflow/dags/data/processed/spotify_transformed.csv
[2025-06-05T01:28:01.269+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:01.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.430 seconds
[2025-06-05T01:28:44.320+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:44.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:28:44.321+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:28:44.321+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:44.951+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:28:44.948+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 42, in <module>
    [t1, t2, t3] >> [t4, t5, t6] >> t7 >> t8 >> t9
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2025-06-05T01:28:44.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:28:44.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.647 seconds
[2025-06-05T01:29:15.018+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:29:15.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:29:15.019+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:29:15.019+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:29:15.546+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:29:15.543+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 42, in <module>
    [t1, t2, t3] >> [t4, t5, t6] >> t7 >> t8 >> t9
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2025-06-05T01:29:15.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:29:15.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.545 seconds
[2025-06-05T01:30:19.460+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:19.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:30:19.462+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:30:19.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:20.031+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:30:20.029+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 42, in <module>
    [t1, t2, t3] >> [t4, t5, t6] >> t7 >> t8 >> t9
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2025-06-05T01:30:20.032+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:20.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.590 seconds
[2025-06-05T01:30:50.188+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:50.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_pipeline.py for tasks to queue
[2025-06-05T01:30:50.189+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:30:50.189+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:50.648+0000] {logging_mixin.py:188} INFO - [2025-06-05T01:30:50.646+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_pipeline.py", line 42, in <module>
    [t1, t2, t3] >> [t4, t5, t6] >> t7 >> t8 >> t9
TypeError: unsupported operand type(s) for >>: 'list' and 'list'
[2025-06-05T01:30:50.649+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_pipeline.py
[2025-06-05T01:30:54.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_pipeline.py took 0.475 seconds
